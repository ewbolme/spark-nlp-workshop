{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NO.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **Detect entities in Norwegian text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "CGJktFHdHL1n",
    "outputId": "0f0f1a83-95ba-4f26-bc37-58ac4be82532"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install SparkNLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCIT5VLxS3I1"
   },
   "source": [
    "## 2. Start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sw-t1zxlHTB7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 3. Select the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLuDz_t40be4"
   },
   "outputs": [],
   "source": [
    "# If you change the model, re-run all the cells below.\n",
    "# Applicable models: norne_840B_300, norne_6B_300, norne_6B_100\n",
    "MODEL_NAME = \"norne_840B_300\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 4. Some sample examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples to be transformed as strings in this list\n",
    "text_list = [\n",
    "    \"\"\"William Henry Gates III (født 28. oktober 1955) er en amerikansk forretningsmagnat, programvareutvikler, investor og filantrop. Han er mest kjent som medgründer av Microsoft Corporation. I løpet av sin karriere hos Microsoft hadde Gates stillingene som styreleder, administrerende direktør (CEO), president og sjef programvarearkitekt, samtidig som han var den største individuelle aksjonæren fram til mai 2014. Han er en av de mest kjente gründere og pionerene i mikrodatarevolusjon på 1970- og 1980-tallet. Han er født og oppvokst i Seattle, Washington, og grunnla Microsoft sammen med barndomsvennen Paul Allen i 1975, i Albuquerque, New Mexico; det fortsatte å bli verdens største programvare for datamaskinprogramvare. Gates ledet selskapet som styreleder og administrerende direktør til han gikk av som konsernsjef i januar 2000, men han forble styreleder og ble sjef for programvarearkitekt. I løpet av slutten av 1990-tallet hadde Gates blitt kritisert for sin forretningstaktikk, som har blitt ansett som konkurransedyktig. Denne uttalelsen er opprettholdt av en rekke dommer. I juni 2006 kunngjorde Gates at han skulle gå over til en deltidsrolle hos Microsoft og på heltid ved Bill & Melinda Gates Foundation, den private veldedige stiftelsen som han og kona, Melinda Gates, opprettet i 2000. [ 9] Han overførte gradvis arbeidsoppgavene sine til Ray Ozzie og Craig Mundie. Han trakk seg som styreleder for Microsoft i februar 2014 og tiltrådte et nytt verv som teknologirådgiver for å støtte den nyutnevnte administrerende direktøren Satya Nadella.\"\"\",\n",
    "    \"\"\"Mona Lisa er et oljemaleri fra 1500-tallet skapt av Leonardo. Det holdes på Louvre i Paris.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XftYgju4XOw_"
   },
   "source": [
    "## 5. Define Spark NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "lBggF5P8J1gc",
    "outputId": "fcf7c6cd-40b2-4fc5-dc78-2fc07f6a8f17"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "# The wikiner_840B_300 is trained with glove_840B_300, so the embeddings in the\n",
    "# pipeline should match. Same applies for the other available models.\n",
    "if MODEL_NAME == \"wikiner_840B_300\":\n",
    "    embeddings = WordEmbeddingsModel.pretrained('glove_840B_300', lang='xx') \\\n",
    "        .setInputCols(['document', 'token']) \\\n",
    "        .setOutputCol('embeddings')\n",
    "elif MODEL_NAME == \"wikiner_6B_300\":\n",
    "    embeddings = WordEmbeddingsModel.pretrained('glove_6B_300', lang='xx') \\\n",
    "        .setInputCols(['document', 'token']) \\\n",
    "        .setOutputCol('embeddings')\n",
    "elif MODEL_NAME == \"wikiner_6B_100\":\n",
    "    embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
    "        .setInputCols(['document', 'token']) \\\n",
    "        .setOutputCol('embeddings')\n",
    "\n",
    "ner_model = NerDLModel.pretrained(MODEL_NAME, 'no') \\\n",
    "    .setInputCols(['document', 'token', 'embeddings']) \\\n",
    "    .setOutputCol('ner')\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "    .setInputCols(['document', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    ner_model,\n",
    "    ner_converter\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv0abcwhXWC-"
   },
   "source": [
    "## 6. Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYf_9sXDXR4t"
   },
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQY8tAP6XZJL"
   },
   "source": [
    "## 7. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "Ar32BZu7J79X",
    "outputId": "8d28503a-ee82-4ee6-e959-36530081b872"
   },
   "outputs": [],
   "source": [
    "result.select(\n",
    "    F.explode(\n",
    "        F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')\n",
    "    ).alias(\"cols\")\n",
    ").select(\n",
    "    F.expr(\"cols['0']\").alias('chunk'),\n",
    "    F.expr(\"cols['1']['entity']\").alias('ner_label')\n",
    ").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER_NO.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
