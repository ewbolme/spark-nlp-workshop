{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_HEALTHCARE_DE.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **Detect symptoms, treatments and other NERs in German**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uDmeHEFW7_h"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMIDv74CYN0d"
   },
   "source": [
    "Import license keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 1025,
     "status": "ok",
     "timestamp": 1601199621177,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "ttHPIV2JXbIM",
    "outputId": "b92db466-7d76-43fd-8c98-c0989deed918"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQtc1CHaYQjU"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "executionInfo": {
     "elapsed": 69241,
     "status": "ok",
     "timestamp": 1601199690729,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "CGJktFHdHL1n",
    "outputId": "9ac97b4a-572c-49e1-d5a5-14294177b62a"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj5FRDV4YSXN"
   },
   "source": [
    "Import dependencies into Python and start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 86109,
     "status": "ok",
     "timestamp": 1601199711922,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "sw-t1zxlHTB7"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 2. Construct the pipeline\n",
    "\n",
    "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "executionInfo": {
     "elapsed": 121920,
     "status": "ok",
     "timestamp": 1601200121396,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "LLuDz_t40be4",
    "outputId": "a8c09b93-5f06-4cd4-f758-9bcf915d3528"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "# German word embeddings\n",
    "word_embeddings = WordEmbeddingsModel.pretrained('w2v_cc_300d','de', 'clinical/models') \\\n",
    "                    .setInputCols([\"sentence\", 'token'])\\\n",
    "                    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# German NER model\n",
    "clinical_ner = NerDLModel.pretrained('ner_healthcare','de', 'clinical/models') \\\n",
    "          .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "          .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1601200279932,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "    \"\"\"Ja das ist bekannt gewesen. Und die haben sich danach gerichtet. Hatte das Gefühl das er sich schon sehr wohl da gefühlt. Haben das auch von den Betreuern als Rückmeldung erhalten. Er ist zwar immer furchtbar aufgeregt wenn es dann los geht, aber wenn er dann da ist, freut er sich doch. Müssen zwar dann auch meist er sehr lange Autofahrt in Kauf nehmen da es das nicht in unserer Gegend gibt. Aber wenn er wenigstens daran eine Freude, warum nicht.\n",
    "Leute, lest euch diesen Beitrag vollständig durch! Cosma und ich, wir haben unsere Erlebnisse gut dokumentiert. Wir waren am Anfang genauso ratlos, wie du (und noch andere, die hier dieselben Fragen stellem), die Diagnose ist für solche Sachen entweder Depressionen oder Burnout bzw. beides (wenn nichts Körperliches vorliegt). Manche haben noch zusätzlich Angstzustände oder Panikattacken. Die Diagnose sollte allerdings ein Neurologe/Psychiater stellen.\"\"\",\n",
    "    \"\"\"Das ist doch immer eine Überlegung wert. Bis vor kurzem war das sogar noch die Strategie ganzer Länder, u. a. GB. Also ich bin zum Besispiel einer von den süßen Opis, die derzeit bloß nicht an den Eiern gedrückt werden sollen. Ich würde mir tatsächlich eine Ansteckung mit einem einigermaßen moderaten Verlauf wünschen. Dann hätte ich, nach allem was man weiß, u. a. von Rhesusaffen, eine Grundimmunität und könnte rausgehen und meinen Mitmenschen unter die Arme greifen. Ich bin halt alt, aber net unbedingt schwach. Rüstiger Greis, sozusagen\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv0abcwhXWC-"
   },
   "source": [
    "## 4. Use the pipeline to create outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1601200285038,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "TK1DB9JZaPs3"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQY8tAP6XZJL"
   },
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnsMLq9gctSq"
   },
   "source": [
    "Visualize outputs as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 7650,
     "status": "ok",
     "timestamp": 1601200293079,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "Ar32BZu7J79X",
    "outputId": "f6a5eed9-cc60-4fb9-d25b-1febc75cdf4f"
   },
   "outputs": [],
   "source": [
    "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
    "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
    "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
    "result.select(exploded.alias(\"cols\")) \\\n",
    "    .select(select_expression_0, select_expression_1).show(truncate=False)\n",
    "result = result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wdVmoUcdnAk"
   },
   "source": [
    "Functions to display outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5409,
     "status": "ok",
     "timestamp": 1601200293080,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "tFeu7loodcQQ"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import random\n",
    "\n",
    "def get_color():\n",
    "    r = lambda: random.randint(128,255)\n",
    "    return \"#%02x%02x%02x\" % (r(), r(), r())\n",
    "\n",
    "def annotation_to_html(full_annotation):\n",
    "    ner_chunks = full_annotation[0]['ner_chunk']\n",
    "    text = full_annotation[0]['document'][0].result\n",
    "    label_color = {}\n",
    "    for chunk in ner_chunks:\n",
    "        label_color[chunk.metadata['entity']] = get_color()\n",
    "\n",
    "    html_output = \"<div>\"\n",
    "    pos = 0\n",
    "\n",
    "    for n in ner_chunks:\n",
    "        if pos < n.begin and pos < len(text):\n",
    "            html_output += f\"<span class=\\\"others\\\">{text[pos:n.begin]}</span>\"\n",
    "        pos = n.end + 1\n",
    "        html_output += f\"<span class=\\\"entity-wrapper\\\" style=\\\"color: black; background-color: {label_color[n.metadata['entity']]}\\\"> <span class=\\\"entity-name\\\">{n.result}</span> <span class=\\\"entity-type\\\">[{n.metadata['entity']}]</span></span>\"\n",
    "\n",
    "    if pos < len(text):\n",
    "        html_output += f\"<span class=\\\"others\\\">{text[pos:]}</span>\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-piHygJ6dpEa"
   },
   "source": [
    "Display example outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 4102,
     "status": "ok",
     "timestamp": 1601200293860,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "AtbhE24VeG_C",
    "outputId": "514a3153-b06b-45b4-f6a8-ab3a2b61b258"
   },
   "outputs": [],
   "source": [
    "for example in input_list:\n",
    "    annotation_to_html(light_pipeline.fullAnnotate(example))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER_HEALTHCARE_DE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
