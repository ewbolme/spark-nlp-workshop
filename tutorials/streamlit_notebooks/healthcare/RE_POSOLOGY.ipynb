{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/RE_POSOLOGY.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **Detect posology relations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uDmeHEFW7_h"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMIDv74CYN0d"
   },
   "source": [
    "Import license keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1599820758535,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "ttHPIV2JXbIM",
    "outputId": "0e3aa0b3-85cb-4f2f-e34a-1d9437e92d2d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQtc1CHaYQjU"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57073,
     "status": "ok",
     "timestamp": 1599820756966,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "CGJktFHdHL1n",
    "outputId": "7cfa7dfc-3ffc-4c38-c726-c903e2bcb858"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj5FRDV4YSXN"
   },
   "source": [
    "Import dependencies into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1599820844412,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "qUWyj8c6JSPP"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ed6Htm7qDQB3"
   },
   "source": [
    "Start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19605,
     "status": "ok",
     "timestamp": 1599820864325,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "eaSM8-xhDRa4"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 2. Select the Relation Extraction model and construct the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVKr8C2SrkZQ"
   },
   "source": [
    "Select the models:\n",
    "\n",
    "\n",
    "* Posology Relation Extraction models: **posology_re**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18681,
     "status": "ok",
     "timestamp": 1599820864326,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "cK9xxkkfrsLc"
   },
   "outputs": [],
   "source": [
    "# Change this to the model you want to use and re-run the cells below.\n",
    "RE_MODEL_NAME = \"posology_re\"\n",
    "NER_MODEL_NAME = \"ner_posology_large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zweiG2ilZqoR"
   },
   "source": [
    "Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167101,
     "status": "ok",
     "timestamp": 1599821013592,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "LLuDz_t40be4",
    "outputId": "b4ea2fee-8bb5-4a7f-c4ad-3a46444179e3"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentences')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentences']) \\\n",
    "    .setOutputCol('tokens')\n",
    "\n",
    "pos_tagger = PerceptronModel()\\\n",
    "    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentences\", \"tokens\"])\\\n",
    "    .setOutputCol(\"pos_tags\")\n",
    "\n",
    "dependency_parser = DependencyParserModel()\\\n",
    "    .pretrained(\"dependency_conllu\", \"en\")\\\n",
    "    .setInputCols([\"sentences\", \"pos_tags\", \"tokens\"])\\\n",
    "    .setOutputCol(\"dependencies\")\n",
    "\n",
    "embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models')\\\n",
    "    .setInputCols([\"sentences\", \"tokens\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner_model = NerDLModel().pretrained(NER_MODEL_NAME, 'en', 'clinical/models').setInputCols(\"sentences\", \"tokens\", \"embeddings\")\\\n",
    "    .setOutputCol(\"clinical_ner_tags\")   \n",
    "\n",
    "clinical_ner_chunker = NerConverter()\\\n",
    "    .setInputCols([\"sentences\", \"tokens\", \"clinical_ner_tags\"])\\\n",
    "    .setOutputCol(\"clinical_ner_chunks\")\n",
    "\n",
    "clinical_re_Model = RelationExtractionModel()\\\n",
    "    .pretrained(RE_MODEL_NAME, 'en', 'clinical/models')\\\n",
    "    .setInputCols([\"embeddings\", \"pos_tags\", \"clinical_ner_chunks\", \"dependencies\"])\\\n",
    "    .setOutputCol(\"clinical_relations\")\\\n",
    "    .setMaxSyntacticDistance(4)\n",
    "    #.setRelationPairs()#[\"problem-test\", \"problem-treatment\"]) # we can set the possible relation pairs (if not set, all the relations will be calculated)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    pos_tagger,\n",
    "    dependency_parser,\n",
    "    embeddings,\n",
    "    clinical_ner_model,\n",
    "    clinical_ner_chunker,\n",
    "    clinical_re_Model])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipeline_model = pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165372,
     "status": "ok",
     "timestamp": 1599821013594,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "\"\"\"The patient is a 40-year-old white male who presents with a chief complaint of \"chest pain\". The patient is diabetic and has a prior history of coronary artery disease. The patient presents today stating that his chest pain started yesterday evening and has been somewhat intermittent. He has been advised Aspirin 81 milligrams QDay. Humulin N. insulin 50 units in a.m. HCTZ 50 mg QDay. Nitroglycerin 1/150 sublingually PRN chest pain.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gmrjqHSGcJx"
   },
   "source": [
    "# 4. Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 169059,
     "status": "ok",
     "timestamp": 1599821018607,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "xdhgKutMHUoC"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)\n",
    "light_result = light_pipeline.fullAnnotate(input_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIVShVLhI68M"
   },
   "source": [
    "# 5. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "472iBPpK-FvF"
   },
   "source": [
    "helper function for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 168048,
     "status": "ok",
     "timestamp": 1599821018608,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "PQrKey9B-FF_"
   },
   "outputs": [],
   "source": [
    "def get_relations_df (results, rel='clinical_relations'):\n",
    "    rel_pairs=[]\n",
    "    for rel in results[rel]:\n",
    "        rel_pairs.append((\n",
    "          rel.result, \n",
    "          rel.metadata['entity1'], \n",
    "          rel.metadata['entity1_begin'],\n",
    "          rel.metadata['entity1_end'],\n",
    "          rel.metadata['chunk1'], \n",
    "          rel.metadata['entity2'],\n",
    "          rel.metadata['entity2_begin'],\n",
    "          rel.metadata['entity2_end'],\n",
    "          rel.metadata['chunk2'], \n",
    "          rel.metadata['confidence']\n",
    "        ))\n",
    "\n",
    "    rel_df = pd.DataFrame(rel_pairs, columns=['relation','entity1','entity1_begin','entity1_end','chunk1','entity2','entity2_begin','entity2_end','chunk2', 'confidence'])\n",
    "\n",
    "    return rel_df[rel_df.relation!='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2847,
     "status": "ok",
     "timestamp": 1599066000165,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "Qdh2BQaLI7tU",
    "outputId": "db04a7f4-0838-4f5a-ec05-f3844e412553"
   },
   "outputs": [],
   "source": [
    "get_relations_df(light_result[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RE_POSOLOGY.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
