{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/ER_ICDO.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **ICDO coding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uDmeHEFW7_h"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMIDv74CYN0d"
   },
   "source": [
    "Import license keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1601204620273,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "ttHPIV2JXbIM",
    "outputId": "8d102eee-4fa0-41ec-9cd5-f979c9b69be8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQtc1CHaYQjU"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "executionInfo": {
     "elapsed": 67833,
     "status": "ok",
     "timestamp": 1601204688754,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "CGJktFHdHL1n",
    "outputId": "1e3f1b8f-7069-4b0d-8fa1-225224db554b"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj5FRDV4YSXN"
   },
   "source": [
    "Import dependencies into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65646,
     "status": "ok",
     "timestamp": 1601204688756,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "qUWyj8c6JSPP"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed6Htm7qDQB3"
   },
   "source": [
    "Start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20816,
     "status": "ok",
     "timestamp": 1601204709582,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "eaSM8-xhDRa4"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 2. Select the Entity Resolver model and construct the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVKr8C2SrkZQ"
   },
   "source": [
    "Select the models:\n",
    "\n",
    "**ICDO Entity Resolver models:**\n",
    "\n",
    "1.   **chunkresolve_icdo_clinical**\n",
    "\n",
    "**NER models that support neoplasms:**\n",
    "1.   **ner_bionlp**\n",
    "\n",
    "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1601204861444,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "cK9xxkkfrsLc"
   },
   "outputs": [],
   "source": [
    "# Change this to the model you want to use and re-run the cells below.\n",
    "ER_MODEL_NAME = \"chunkresolve_icdo_clinical\"\n",
    "NER_MODEL_NAME = \"ner_bionlp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zweiG2ilZqoR"
   },
   "source": [
    "Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 8988,
     "status": "ok",
     "timestamp": 1601205432824,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "LLuDz_t40be4",
    "outputId": "ac8ab568-6291-46ca-9fd5-b4a1c237c9bd"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentences')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentences']) \\\n",
    "    .setOutputCol('tokens')\n",
    "\n",
    "embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models')\\\n",
    "    .setInputCols([\"sentences\", \"tokens\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner_model = NerDLModel().pretrained(NER_MODEL_NAME, 'en', 'clinical/models').setInputCols(\"sentences\", \"tokens\", \"embeddings\")\\\n",
    "    .setOutputCol(\"clinical_ner_tags\")   \n",
    "\n",
    "# using whitelist to filter out entities\n",
    "clinical_ner_chunker = NerConverter()\\\n",
    "    .setInputCols([\"sentences\", \"tokens\", \"clinical_ner_tags\"])\\\n",
    "    .setOutputCol(\"ner_chunk\").setWhiteList(['Cancer'])\n",
    "\n",
    "chunk_embeddings = ChunkEmbeddings()\\\n",
    "    .setInputCols(\"ner_chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"chunk_embeddings\")\n",
    "\n",
    "entity_resolver = \\\n",
    "    ChunkEntityResolverModel.pretrained(ER_MODEL_NAME,\"en\",\"clinical/models\")\\\n",
    "    .setInputCols(\"tokens\",\"chunk_embeddings\").setOutputCol(\"resolution\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    clinical_ner_model,\n",
    "    clinical_ner_chunker,\n",
    "    chunk_embeddings,\n",
    "    entity_resolver])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipeline_model = pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5804,
     "status": "ok",
     "timestamp": 1601205432825,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "\"\"\"DIAGNOSIS: Left breast adenocarcinoma stage T3 N1b M0, stage IIIA.\n",
    "She has been found more recently to have stage IV disease with metastatic deposits and recurrence involving the chest wall and lower left neck lymph nodes.\n",
    "PHYSICAL EXAMINATION\n",
    "NECK: On physical examination palpable lymphadenopathy is present in the left lower neck and supraclavicular area. No other cervical lymphadenopathy or supraclavicular lymphadenopathy is present.\n",
    "RESPIRATORY: Good air entry bilaterally. Examination of the chest wall reveals a small lesion where the chest wall recurrence was resected. No lumps, bumps or evidence of disease involving the right breast is present.\n",
    "ABDOMEN: Normal bowel sounds, no hepatomegaly. No tenderness on deep palpation. She has just started her last cycle of chemotherapy today, and she wishes to visit her daughter in Brooklyn, New York. After this she will return in approximately 3 to 4 weeks and begin her radiotherapy treatment at that time.\"\"\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gmrjqHSGcJx"
   },
   "source": [
    "# 4. Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6186,
     "status": "ok",
     "timestamp": 1601205434366,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "xdhgKutMHUoC"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)\n",
    "light_result = light_pipeline.fullAnnotate(input_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIVShVLhI68M"
   },
   "source": [
    "# 5. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "472iBPpK-FvF"
   },
   "source": [
    "Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "executionInfo": {
     "elapsed": 5561,
     "status": "ok",
     "timestamp": 1601205435739,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "Qdh2BQaLI7tU",
    "outputId": "eee35830-c127-4dde-b1cb-cd4759c0c43c"
   },
   "outputs": [],
   "source": [
    "result.select(\n",
    "    F.explode(\n",
    "        F.arrays_zip('ner_chunk.result', \n",
    "                     'ner_chunk.begin',\n",
    "                     'ner_chunk.end',\n",
    "                     'ner_chunk.metadata',\n",
    "                     'resolution.metadata', 'resolution.result')\n",
    "    ).alias('cols')\n",
    ").select(\n",
    "    F.expr(\"cols['0']\").alias('chunk'),\n",
    "    F.expr(\"cols['1']\").alias('begin'),\n",
    "    F.expr(\"cols['2']\").alias('end'),\n",
    "    F.expr(\"cols['3']['entity']\").alias('entity'),\n",
    "    F.expr(\"cols['4']['resolved_text']\").alias('idco_description'),\n",
    "    F.expr(\"cols['5']\").alias('icdo_code'),\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w6-BQ0MFL9Y"
   },
   "source": [
    "Light Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 2990,
     "status": "ok",
     "timestamp": 1601205435740,
     "user": {
      "displayName": "Hasham Ul Haq",
      "photoUrl": "",
      "userId": "10508284328555930330"
     },
     "user_tz": -300
    },
    "id": "LSukuO5eE1cZ",
    "outputId": "eed7e4b8-b206-4b83-ff9f-c5a4b4f4c164"
   },
   "outputs": [],
   "source": [
    "light_result[0]['resolution']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ER_ICDO.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
