{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4b_2KemgDWf"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/CONTEXTUAL_SPELL_CHECKER.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnZG0I4ogNLI"
   },
   "source": [
    "# **Spell checking for clinical documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yjs3mqUJgNQM"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apjCmRyjgQll"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAiXj3DOfyZ-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2phEj9SygX4n"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "bGQnBVvvbHH_",
    "outputId": "15492942-e479-427e-9e14-a56c278e1014"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3Ur62RrgaxX"
   },
   "source": [
    "Import dependencies into Python and start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "br9cSI8_gbWw"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUP6-XeQgeQW"
   },
   "source": [
    "## 2. Select the NER model and construct the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "taOqLG1Ogc3D",
    "outputId": "ff5267a1-f448-4a81-c5fc-40866fff67ed"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = RecursiveTokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token') \\\n",
    "    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"]) \\\n",
    "    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"â€˜s\"])\n",
    "\n",
    "spell_model = ContextSpellCheckerModel.pretrained('spellcheck_clinical', 'en', 'clinical/models') \\\n",
    "    .setInputCols('token') \\\n",
    "    .setOutputCol('corrected')\n",
    "\n",
    "finisher = Finisher().setInputCols('corrected')\n",
    "\n",
    "light_pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    spell_model,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    spell_model\n",
    "])\n",
    "\n",
    "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
    "pipeline_model = full_pipeline.fit(empty_df)\n",
    "light_pipeline_model = LightPipeline(light_pipeline.fit(empty_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_DzGuMPibKr"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7yPd884i_XQ"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "    \"The pateint is a 5-mont-old infnt who presented initially on Monday with a cold, cugh, and runny nse for 2 days. Mom states she had no fevr. Her appetite was good but she was spitting up a lot. She had no difficulty breathin and her cough was described as dry and hacky. At that time, pysicl exam showed a right TM, which was red. Left TM was okay. She was fairly congsted but looked happy and playful. She was started on Amxil and Aldx and we told to recheck in 2 weaks to recheck her ear. Mom returned to clinic again today because she got much worse ovrnght. She was having dificlty breathing. She was much more congested and her apetit had decrsed significantly today. She also spked a tempratre yesterday of 102.6 and always hvng trouble sleping scondry to congestion.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvyOmrgHjO5J"
   },
   "source": [
    "## 4. Use the pipeline to create outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICREynF-jzn8"
   },
   "source": [
    "Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLbrPvC3jOSw"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({'text': input_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhlbvs1Dj1ck"
   },
   "source": [
    "Light Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YulVrYgAj2ex"
   },
   "outputs": [],
   "source": [
    "# Light pipelines use plain string inputs instead of data frame inputs\n",
    "light_result = light_pipeline_model.annotate(input_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uk72hQGqjX3f"
   },
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J9JDK9_EjaF_"
   },
   "source": [
    "Visualize comparison as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "FY_7D9RFjlQS",
    "outputId": "952d249f-2713-46d2-e511-1b3c8809322e"
   },
   "outputs": [],
   "source": [
    "exploded = F.explode(F.arrays_zip('token.result', 'corrected.result'))\n",
    "select_expression_0 = F.expr(\"cols['0']\").alias(\"original\")\n",
    "select_expression_1 = F.expr(\"cols['1']\").alias(\"corrected\")\n",
    "result.select(exploded.alias(\"cols\")) \\\n",
    "    .select(select_expression_0, select_expression_1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yItQfZmhcji"
   },
   "source": [
    "Vizualise light pipeline and finished result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9zHSiB0skP83",
    "outputId": "c2b05514-eff9-45f4-e50d-278bcef2bc48"
   },
   "outputs": [],
   "source": [
    "# This finished result does not need parsing and can directly be used in any\n",
    "# other task\n",
    "light_result['corrected']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CONTEXTUAL_SPELL_CHECKER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
