{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_DEMOGRAPHICS.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **Detect demographic information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uDmeHEFW7_h"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMIDv74CYN0d"
   },
   "source": [
    "Import license keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttHPIV2JXbIM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQtc1CHaYQjU"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "CGJktFHdHL1n",
    "outputId": "1882c7b5-4484-43c8-c1e2-84578876d53f"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj5FRDV4YSXN"
   },
   "source": [
    "Import dependencies into Python and start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "sw-t1zxlHTB7",
    "outputId": "272eddd7-e21f-4504-af31-8fe8b8c8ca0a"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 2. Select the NER model and construct the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbWioxCasOXH"
   },
   "source": [
    "Select the NER model - Demographics models: **ner_deid_enriched, ner_deid_large, ner_jsl**\n",
    "\n",
    "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeSfy_oGsTL6"
   },
   "outputs": [],
   "source": [
    "# You can change this to the model you want to use and re-run cells below.\n",
    "# Demographics models: ner_deid_enriched, ner_deid_large, ner_jsl\n",
    "MODEL_NAME = \"ner_deid_enriched\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zweiG2ilZqoR"
   },
   "source": [
    "Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLuDz_t40be4"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models') \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('embeddings')\n",
    "\n",
    "clinical_ner = NerDLModel.pretrained(MODEL_NAME, 'en', 'clinical/models') \\\n",
    "    .setInputCols(['sentence', 'token', 'embeddings']) \\\n",
    "    .setOutputCol('ner')\n",
    "\n",
    "ner_converter = NerConverter()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "    \"\"\"HISTORY OF PRESENT ILLNESS: Mr. Smith is a 60-year-old white male veteran with multiple comorbidities, who has a history of bladder cancer diagnosed approximately two years ago by the VA Hospital. He underwent a resection there. He was to be admitted to the Day Hospital for cystectomy. He was seen in Urology Clinic and Radiology Clinic on 02/04/2003.\n",
    "\n",
    "HOSPITAL COURSE: Mr. Smith presented to the Day Hospital in anticipation for Urology surgery. On evaluation, EKG, echocardiogram was abnormal, a Cardiology consult was obtained. A cardiac adenosine stress MRI was then proceeded, same was positive for inducible ischemia, mild-to-moderate inferolateral subendocardial infarction with peri-infarct ischemia. In addition, inducible ischemia seen in the inferior lateral septum. Mr. Smith underwent a left heart catheterization, which revealed two vessel coronary artery disease. The RCA, proximal was 95% stenosed and the distal 80% stenosed. The mid LAD was 85% stenosed and the distal LAD was 85% stenosed. There was four Multi-Link Vision bare metal stents placed to decrease all four lesions to 0%. Following intervention, Mr. Smith was admitted to 7 Ardmore Tower under Cardiology Service under the direction of Dr. Hart. Mr. Smith had a noncomplicated post-intervention hospital course. He was stable for discharge home on 02/07/2003 with instructions to take Plavix daily for one month and Urology is aware of the same.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv0abcwhXWC-"
   },
   "source": [
    "## 4. Use the pipeline to create outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK1DB9JZaPs3"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQY8tAP6XZJL"
   },
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnsMLq9gctSq"
   },
   "source": [
    "Visualize outputs as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "Ar32BZu7J79X",
    "outputId": "6870a43f-a772-4825-e6b5-f30270bbcae6"
   },
   "outputs": [],
   "source": [
    "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
    "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
    "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
    "result.select(exploded.alias(\"cols\")) \\\n",
    "    .select(select_expression_0, select_expression_1).show(truncate=False)\n",
    "result = result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wdVmoUcdnAk"
   },
   "source": [
    "Functions to display outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFeu7loodcQQ"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import random\n",
    "\n",
    "def get_color():\n",
    "    r = lambda: random.randint(128,255)\n",
    "    return \"#%02x%02x%02x\" % (r(), r(), r())\n",
    "\n",
    "def annotation_to_html(full_annotation):\n",
    "    ner_chunks = full_annotation[0]['ner_chunk']\n",
    "    text = full_annotation[0]['document'][0].result\n",
    "    label_color = {}\n",
    "    for chunk in ner_chunks:\n",
    "        label_color[chunk.metadata['entity']] = get_color()\n",
    "\n",
    "    html_output = \"<div>\"\n",
    "    pos = 0\n",
    "\n",
    "    for n in ner_chunks:\n",
    "        if pos < n.begin and pos < len(text):\n",
    "            html_output += f\"<span class=\\\"others\\\">{text[pos:n.begin]}</span>\"\n",
    "        pos = n.end + 1\n",
    "        html_output += f\"<span class=\\\"entity-wrapper\\\" style=\\\"color: black; background-color: {label_color[n.metadata['entity']]}\\\"> <span class=\\\"entity-name\\\">{n.result}</span> <span class=\\\"entity-type\\\">[{n.metadata['entity']}]</span></span>\"\n",
    "\n",
    "    if pos < len(text):\n",
    "        html_output += f\"<span class=\\\"others\\\">{text[pos:]}</span>\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-piHygJ6dpEa"
   },
   "source": [
    "Display example outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "AtbhE24VeG_C",
    "outputId": "05d8fae4-bf84-45c3-e047-39c7448e58ee"
   },
   "outputs": [],
   "source": [
    "for example in input_list:\n",
    "    annotation_to_html(light_pipeline.fullAnnotate(example))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER_DEMOGRAPHICS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
