{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxLWnneBSApv"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/CONTEXTUAL_PARSER.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsFQzCJuSEa4"
   },
   "source": [
    "# **Detect demographics and vital signs using rules**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbk1cNOH__M5"
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2-xCo1zObqa"
   },
   "source": [
    "Open license keys so the licensed models can be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iW6JfkPdNnG4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ii9GkjPgOXzM"
   },
   "source": [
    "\n",
    "Install and import necessary dependencies for Spark NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "_vcxg-Hgb3Z_",
    "outputId": "5adf68a2-1c68-4817-8308-023f07264ac5"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "jsl_secret = \"2.5.5-4f4b7f600f8ba3cdc5973a6baa47b901b0c8d8a3\"\n",
    "jsl_version = jsl_secret.split('-')[0]\n",
    "! pip install --ignore-installed -q spark-nlp\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$jsl_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5L-gJtxibuBe"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(jsl_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk4bGqNcSXv6"
   },
   "outputs": [],
   "source": [
    "# make a directory for the rules we will create later\n",
    "! mkdir rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8M6YOniYU0O"
   },
   "source": [
    "## HTML display of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyv-aZL6JDtu"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmxsbggxVYUd"
   },
   "outputs": [],
   "source": [
    "def get_color():\n",
    "    r = lambda: random.randint(128,255)\n",
    "    return \"#%02x%02x%02x\" % (r(), r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN33NTAMYQL6"
   },
   "outputs": [],
   "source": [
    "def annotation_to_html(full_annotation):\n",
    "    annotation = full_annotation[0]\n",
    "    text = annotation['document'][0].result\n",
    "    ner_chunks = []\n",
    "    label_color = {}\n",
    "    unified_entities = {'entity': []}\n",
    "    for entity_name in annotation.keys():\n",
    "        if (\"entity\" in entity_name) and (len(annotation[entity_name]) > 0):\n",
    "            ner_chunks.append(entity_name)\n",
    "            label = annotation[entity_name][0].metadata['field']\n",
    "            label_color[label] = get_color()\n",
    "            unified_entities['entity'].extend(annotation[entity_name])\n",
    "    unified_entities['entity'].sort(key=lambda x: x.begin, reverse=False)\n",
    "\n",
    "    html_output = \"<div>\"\n",
    "    pos = 0\n",
    "\n",
    "    for n in unified_entities['entity']:\n",
    "        if pos < n.begin and pos < len(text):\n",
    "            html_output += f\"<span class=\\\"others\\\">{text[pos:n.begin]}</span>\"\n",
    "        pos = n.end + 1\n",
    "        html_output += f\"<span class=\\\"entity-wrapper\\\" style=\\\"color: black; background-color: {label_color[n.metadata['field']]}\\\"> <span class=\\\"entity-name\\\">{n.result}</span> <span class=\\\"entity-type\\\">[{n.metadata['field']}]</span></span>\"\n",
    "\n",
    "    if pos < len(text):\n",
    "        html_output += f\"<span class=\\\"others\\\">{text[pos:]}</span>\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDBxU88hRE3p"
   },
   "source": [
    "## Rule creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRjCdDuDxkX"
   },
   "source": [
    "### Vital signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAI5XZ76UfJn"
   },
   "outputs": [],
   "source": [
    "# regex matches any number between 90 and 109 inclusive, including decimals\n",
    "\n",
    "with open('rules/temperature.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'entity': \"Temperature\",\n",
    "        'ruleScope': \"sentence\",\n",
    "        'matchScope': \"token\",\n",
    "        'regex': \"\\\\b((9[0-9])|(10[0-9]))((\\\\.|,)[0-9]+)?\\\\b\",\n",
    "        'prefix': [\"temperature\", \"fever\"],\n",
    "        'suffix': [\"Fahrenheit\", \"Celsius\", \"centigrade\", \"F\", \"C\"],\n",
    "        'contextLength': 30\n",
    "    }, f)\n",
    "\n",
    "temperature_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_temperature') \\\n",
    "    .setJsonPath('/content/rules/temperature.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0RIzxM9KWOp"
   },
   "outputs": [],
   "source": [
    "# regex matches any number in the format S/D where S is between 40 and 199\n",
    "# and D is between 30 and 150\n",
    "\n",
    "with open('rules/blood_pressure.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'entity': \"Blood pressure\",\n",
    "        'ruleScope': \"sentence\",\n",
    "        'matchScope': \"token\",\n",
    "        'regex': \"\\\\b([4-9]|1\\\\d)\\\\d\\\\/([3-9]|1[0-4])\\\\d\\\\b\",\n",
    "        'contextException': [\"exam\", \"test\", \"scored\", \"score\", \"scores\"],\n",
    "        'exceptionDistance': 15\n",
    "    }, f)\n",
    "\n",
    "blood_pressure_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_blood_pressure') \\\n",
    "    .setJsonPath('/content/rules/blood_pressure.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxxCsv-eHsw6"
   },
   "outputs": [],
   "source": [
    "# regex matches any integer between 40 and 189 inclusive\n",
    "\n",
    "with open('rules/pulse.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'entity': \"Pulse\",\n",
    "        'ruleScope': \"sentence\",\n",
    "        'matchScope': \"token\",\n",
    "        'regex': \"\\\\b(([4-9]\\\\d)|(1\\\\d\\\\d))\\\\b\",\n",
    "        'prefix': [\"pulse\", \"heart\"],\n",
    "        'suffix': [\"beats\"],\n",
    "        'contextLength': 20\n",
    "    }, f)\n",
    "\n",
    "pulse_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_pulse') \\\n",
    "    .setJsonPath('/content/rules/pulse.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0XtHxS0Jaoa"
   },
   "outputs": [],
   "source": [
    "# regex matches any number between 1 and 79 inclusive, not including decimals\n",
    "\n",
    "with open('rules/respiration_rate.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'entity': \"Respiration rate\",\n",
    "        'ruleScope': \"sentence\",\n",
    "        'matchScope': \"token\",\n",
    "        'regex': \"\\\\b(([1-9])|([0-7][0-9]))\\\\b\",\n",
    "        'prefix': [\"respiration\", \"respirations\", \"respiratory\"],\n",
    "        'suffix': [\"breath\", \"breaths\"],\n",
    "        'contextLength': 25,\n",
    "        'contextException': [\"pulse\", \"beats\", \"heart\",\n",
    "            \"Fahrenheit\", \"Celsius\", \"centigrade\", \"degrees\", \"temperature\"],\n",
    "        'exceptionDistance': 15\n",
    "    }, f)\n",
    "\n",
    "respirations_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_respirations') \\\n",
    "    .setJsonPath('/content/rules/respiration_rate.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0DHSPj5-aY1"
   },
   "outputs": [],
   "source": [
    "# regex matches any number between 50 and 100 inclusive, including decimals, and\n",
    "# including percent sign if present\n",
    "\n",
    "with open('rules/o2_saturation.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'entity': \"O2 saturation\",\n",
    "        'ruleScope': \"sentence\",\n",
    "        'matchScope': \"token\",\n",
    "        'regex': \"\\\\b(([5-9][0-9])|(100))(\\\\.[0-9]+)?%?\\\\b\",\n",
    "        'prefix': [\"saturation\", \"saturating\", \"saturated\", \"saturate\",\n",
    "                   \"oxygen\", \"oximetry\", \"oximeter\", \"air\", \"O2\"],\n",
    "        'suffix': [\"oxygen\", \"saturation\", \"air\"],\n",
    "        'contextLength': 25,\n",
    "        'contextException': [\"year\", \"years\", \"old\",\n",
    "            \"Fahrenheit\", \"Celsius\", \"centigrade\", \"degrees\", \"temperature\",\n",
    "            \"pressure\", \"nonrebreather\", \"pulse\", \"beats\"],\n",
    "        'exceptionDistance': 15\n",
    "    }, f)\n",
    "\n",
    "saturation_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_saturation') \\\n",
    "    .setJsonPath('/content/rules/o2_saturation.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmyfDJgdEAuk"
   },
   "source": [
    "### Dates and money amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9yaduPKD_Rq"
   },
   "outputs": [],
   "source": [
    "# regex matches numerical dates separated by slashes or dashes, with at least a\n",
    "# valid month and day and optionally a year\n",
    "\n",
    "date_rule = {\n",
    "    'entity': \"Date - short\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"\\\\b[0-3]?[0-9](\\\\/|\\\\-)[0-3]?[0-9]((\\\\/|\\\\-)((19)|(20))?([0-9][0-9]))?\\\\b\",\n",
    "    'contextLength': 20,\n",
    "    'contextException': [\"pressure\", \"rate\", \"when\",\n",
    "        \"score\", \"exam\", \"test\", \"tested\", \"tests\", \"MMSE\"],\n",
    "    'exceptionDistance': 20\n",
    "}\n",
    "\n",
    "with open('rules/date_-_short.json', 'w') as f:\n",
    "    json.dump(date_rule, f)\n",
    "\n",
    "date_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_date') \\\n",
    "    .setJsonPath('/content/rules/date_-_short.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ej_vcCKzD_Jp"
   },
   "outputs": [],
   "source": [
    "# regex identifies numbers from 0 to 39, optionally ending in \"rd\", \"nd\", or\n",
    "# \"th\"\n",
    "\n",
    "date_rule2 = {\n",
    "    'entity': \"Date - long\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"\\\\b[0-3]?[0-9]((th)|(nd)|(rd))?(,|\\\\b)\",\n",
    "    'prefix': [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\",\n",
    "        \"august\", \"september\", \"october\", \"november\", \"december\", \"jan\", \"feb\",\n",
    "        \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'suffix': [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\",\n",
    "        \"august\", \"september\", \"october\", \"november\", \"december\", \"jan\", \"feb\",\n",
    "        \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'contextLength': 15\n",
    "}\n",
    "\n",
    "with open('rules/date_-_long.json', 'w') as f:\n",
    "    json.dump(date_rule2, f)\n",
    "\n",
    "date_contextual_parser2 = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_date2') \\\n",
    "    .setJsonPath('/content/rules/date_-_long.json') \\\n",
    "    .setCaseSensitive(True) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uiUFB9PGFtFc"
   },
   "outputs": [],
   "source": [
    "# regex matches numbers, including those broken up by commas or periods,\n",
    "# prefixed by a \"$\", \"£\", or \"€\" and ending in a digit\n",
    "\n",
    "money_rule = {\n",
    "    'entity': \"Money - short\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"[£€\\\\$]([0-9\\\\.,]*[0-9])\"\n",
    "}\n",
    "\n",
    "with open('rules/money_-_short.json', 'w') as f:\n",
    "    json.dump(money_rule, f)\n",
    "\n",
    "money_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_money') \\\n",
    "    .setJsonPath('/content/rules/money_-_short.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0T42HixpFsb-"
   },
   "outputs": [],
   "source": [
    "# regex matches numbers, including those broken up by commas or periods,\n",
    "# ending in a digit\n",
    "# NOTE: suffix will not match phrases like \"17 pounds\" because of possible\n",
    "# confusion with units of weight.\n",
    "\n",
    "money_rule2 = {\n",
    "    'entity': \"Money - long\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"[0-9\\\\.,]*[0-9]\",\n",
    "    'suffix': [\"dollars\", \"euros\", \"cents\", \"pence\", \"USD\", \"EUR\", \"GBP\"],\n",
    "    'contextLength': 15\n",
    "}\n",
    "\n",
    "with open('rules/money_-_long.json', 'w') as f:\n",
    "    json.dump(money_rule2, f)\n",
    "\n",
    "money_contextual_parser2 = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_money2') \\\n",
    "    .setJsonPath('/content/rules/money_-_long.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QSF1yJw7FNR5"
   },
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZpBTrqyFPfo"
   },
   "outputs": [],
   "source": [
    "gender_dictionary = \"\"\"female,female,she,her,hers,girl,woman,old-lady,lady\n",
    "male,male,man,gentleman,boy,he,him,his\n",
    "neutral,neutral,gender-neutral,agender,nonbinary,non-binary\"\"\"\n",
    "\n",
    "gender_rule = {\n",
    "    'entity': \"Gender\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'completeMatchRegex': \"true\"\n",
    "}\n",
    "\n",
    "with open('rules/gender.csv', 'w') as f:\n",
    "    f.write(gender_dictionary)\n",
    "\n",
    "with open('rules/gender.json', 'w') as f:\n",
    "    json.dump(gender_rule, f)\n",
    "\n",
    "gender_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_gender') \\\n",
    "    .setJsonPath('/content/rules/gender.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False) \\\n",
    "    .setDictionary('/content/rules/gender.csv',\n",
    "                   read_as=ReadAs.TEXT,\n",
    "                   options={'delimiter': \",\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Mc6RDJAFQrO"
   },
   "outputs": [],
   "source": [
    "# regex matches any number followed by \"y/o\" or any form of \"-[timespan]-old\"\n",
    "\n",
    "age_rule = {\n",
    "    'entity': \"Age - short\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"\\\\d+(y\\\\/o|-(year|month|week|day)s?-old)\"\n",
    "}\n",
    "\n",
    "with open('rules/age_-_short.json', 'w') as f:\n",
    "    json.dump(age_rule, f)\n",
    "\n",
    "age_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_age') \\\n",
    "    .setJsonPath('/content/rules/age_-_short.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jg6X7EDAVhbQ"
   },
   "outputs": [],
   "source": [
    "# regex detects any number from 0 to 109\n",
    "\n",
    "age_rule2 = {\n",
    "    'entity': \"Age - long\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"\\\\b(\\\\d?\\\\d|10\\\\d)\\\\b\",\n",
    "    'prefix': [\"age\"],\n",
    "    'suffix': [\"age\", \"old\",\n",
    "        \"y/o\", \"year-old\", \"years-old\", \"month-old\", \"months-old\"],\n",
    "    'contextLength': 15\n",
    "}\n",
    "\n",
    "with open('rules/age_-_long.json', 'w') as f:\n",
    "    json.dump(age_rule2, f)\n",
    "\n",
    "age_contextual_parser2 = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_age2') \\\n",
    "    .setJsonPath('/content/rules/age_-_long.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elNqvKHSFRGS"
   },
   "outputs": [],
   "source": [
    "# regex matches heights in the form F'II\", where F is any number from 0 to 7 and\n",
    "# FF is any number from 0 to 12, with an optional leading zero. the quotation\n",
    "# mark at the end is optional.\n",
    "\n",
    "# healthy appearing woman: 5 foot and 6 inches tall\n",
    "# pleasant elderly woman: Height 4 feet 11 inches\n",
    "# social history: Height: 21 inches\n",
    "\n",
    "height_rule = {\n",
    "    'entity': \"Height - short\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"[0-7]'((0?[0-9])|(1(0|1)))\\\"?\"\n",
    "}\n",
    "\n",
    "with open('rules/height_-_short.json', 'w') as f:\n",
    "    json.dump(height_rule, f)\n",
    "\n",
    "height_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_height') \\\n",
    "    .setJsonPath('/content/rules/height_-_short.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAhEzdVKGBqP"
   },
   "outputs": [],
   "source": [
    "# matches numbers from 0 to 249, optionally with a decimal or unit of\n",
    "# measurement trailing.\n",
    "# alternatively, matches a spelled-out number between one and nine.\n",
    "\n",
    "height_rule2 = {\n",
    "    'entity': \"Height - long\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'completeMatchRegex': \"true\",\n",
    "    'regex': \"\\\\b([1-2]?\\\\d?\\\\d(\\\\.\\\\d|cm|ft|\\\\.\\\\d{1,2}m|in)?|one|two|three|four|five|six|seven|eight|nine)\\\\b\",\n",
    "    'prefix': [\"stand\", \"stands\", \"stood\", \"height\", \"tall\"],\n",
    "    'suffix': [\"tall\"],\n",
    "    'contextLength': 20,\n",
    "    'contextException': [\"pressure\"],\n",
    "    'exceptionDistance': 25\n",
    "}\n",
    "\n",
    "with open('rules/height_-_long.json', 'w') as f:\n",
    "    json.dump(height_rule2, f)\n",
    "\n",
    "height_contextual_parser2 = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_height2') \\\n",
    "    .setJsonPath('/content/rules/height_-_long.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwMKM9MvFRZP"
   },
   "outputs": [],
   "source": [
    "# regex matches numbers between 0 and 2999 (high numbers enabled because birth\n",
    "# weights are sometimes written like \"1102\"), with up to one decimal and\n",
    "# optionally followed by \"lb\", \"#\" or \"kg\" (with or without an \"s\" trailing) and\n",
    "# optionally followed by a number of ounces from 0 to 19.\n",
    "\n",
    "# disable the contextException to match more weights other than the patient's\n",
    "# body weight, such as weight gains or weights of objects.\n",
    "\n",
    "weight_rule = {\n",
    "    'entity': \"Weight\",\n",
    "    'ruleScope': \"sentence\",\n",
    "    'matchScope': \"token\",\n",
    "    'regex': \"\\\\b(\\\\d{1,3}(\\\\.\\\\d)?(((kg)|(#|lb))s?)?(1?\\\\doz)?|[0-2]\\\\d{3})\\\\b\",\n",
    "    'prefix': [\"weighs\", \"weighed\", \"weight\"],\n",
    "    'suffix': [\"pounds\", \"lbs\", \"lb\", \"#\", \"#s\", \"kg\", \"kgs\", \"oz\",\n",
    "               \"kilograms\", \"kilos\", \"ounces\"],\n",
    "    'contextLength': 15,\n",
    "    'contextException': [\"gain\", \"g\", \"gram\", \"grams\",\n",
    "                         \"mg\", \"milligram\", \"milligrams\",\n",
    "                         \"BMI\", \"gain\", \"gains\", \"gained\", \"gaining\",\n",
    "                         \"lose\", \"lost\", \"loses\", \"losing\",\n",
    "                         \"temperature\", \"pulse\", \"height\"],\n",
    "    'exceptionDistance': 25\n",
    "}\n",
    "\n",
    "with open('rules/weight.json', 'w') as f:\n",
    "    json.dump(weight_rule, f)\n",
    "\n",
    "weight_contextual_parser = ContextualParserApproach() \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('entity_weight') \\\n",
    "    .setJsonPath('/content/rules/weight.json') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setContextMatch(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfjxMjz8dEgM"
   },
   "source": [
    "## Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gv6wg-YydBQh"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['sentence']) \\\n",
    "    .setOutputCol('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjkdEV_uU2vQ"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    temperature_contextual_parser,\n",
    "    blood_pressure_contextual_parser,\n",
    "    pulse_contextual_parser,\n",
    "    respirations_contextual_parser,\n",
    "    saturation_contextual_parser,\n",
    "    date_contextual_parser,\n",
    "    date_contextual_parser2,\n",
    "    money_contextual_parser,\n",
    "    money_contextual_parser2,\n",
    "    gender_contextual_parser,\n",
    "    age_contextual_parser,\n",
    "    age_contextual_parser2,\n",
    "    height_contextual_parser,\n",
    "    height_contextual_parser2,\n",
    "    weight_contextual_parser\n",
    "])\n",
    "\n",
    "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
    "pipeline_model = pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_2xM8qjAepx"
   },
   "source": [
    "## Example generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ExSU4fwGd4bC"
   },
   "source": [
    "Create input and output file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLBXalJ-aKH7"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ContextualParser\"\n",
    "\n",
    "INPUT_FILE_PATH = f\"inputs/{MODEL_NAME}/\"\n",
    "OUTPUT_FILE_PATH = f\"outputs/{MODEL_NAME}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RhQ9mTrwd7ux"
   },
   "source": [
    "Select example inputs that highlight the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssgo1K1Hcqx-"
   },
   "outputs": [],
   "source": [
    "example_inputs = [\n",
    "    \"\"\"On examination today, this is a pleasant and healthy appearing woman.\n",
    "VITAL SIGNS: Blood pressure 154/72, heart rate 87, temperature 98.8, and weight 153 pounds. Pain is 0/10.\n",
    "HEAD: Head is normocephalic and atraumatic. Head circumference is 54 cm, which is in the 10-25th percentile for a woman who is 5 foot and 6 inches tall and 153 lbs.\"\"\",\n",
    "    \"\"\"GENERAL: She is a pleasant elderly woman, currently in no acute distress.\n",
    "VITAL SIGNS: Height 4 feet 11 inches, weight 128 pounds, temperature 97.2 degrees Fahrenheit, blood pressure 142/70, pulse 47, respiratory rate 16, and O2 saturation 100%\"\"\",\n",
    "    \"\"\"On examination today, this is a pleasant 81-year-old man who is brought back from the clinic waiting area in a wheelchair. He is well developed, well nourished, and kempt.\n",
    "Vital Signs: Temperature 96.7, pulse 62, respirations 16, blood pressure 123/71, and weight 184.\n",
    "Head: The head is normocephalic and atraumatic.\"\"\",\n",
    "    \"\"\"The baby is an ex-32 weeks small for gestational age infant with birth weight 1102. Baby was born at ABCD Hospital at 1333 on 07/14/2006. Mother is a 20-year-old gravida 1, para 0 female who received prenatal care. Prenatal course was complicated by low amniotic fluid index and hypertension. She was evaluated for evolving preeclampsia and had a C-section secondary to the nonreassuring fetal status. Baby delivered operatively, Apgar scores were 8 and 9 initially taken to level 2 satellite nursery and arrangements were to transfer to Children's Hospital. Infant was transferred to Children's Hospital for higher level of care, stayed at Children's Hospital for approximately 2 weeks, and was transferred back to ABCD where he stayed until he was discharged on 08/16/2006.\"\"\",\n",
    "    \"\"\"SOCIAL HISTORY: The patient lives at home with 23-year-old mother, who is a homemaker and 24-year-old father, John, who is a supervisor at Excel. The family lives in Bentley, Kansas. No smoking in the home. Family does have one pet cat.\n",
    "REVIEW OF SYSTEMS: As per HPI, otherwise, negative.\n",
    "OBJECTIVE: Weight: 7 pounds 12 ounces. Height: 21 inches. Head circumference: 35 cm. Temperature: 97.2 degrees. Pulse: 64 beats per minute. Blood pressure 104/63.\n",
    "General: Well-developed, well-nourished, cooperative, alert, interactive 2-week-old white female in no acute distress. Temperature is significantly down from 101.2 degrees two days ago\"\"\",\n",
    "    \"\"\"The patient was reluctant to use medicine. She stated that she felt uncomfortable using pills that cost $20 each. We discussed getting support if $20 per dose was a financial hardship for her.\"\"\",\n",
    "    \"\"\"I had the pleasure of meeting Ms. ABC for evaluation for bariatric surgery. As you know she is a pleasant 54-year-old female who has multiple medical problems and is seeking evaluation for laparoscopic gastric banding. I saw her on October 3, 2008 in the office after she had attended a Fairfield County Bariatrics and Surgical Specialists seminar. She is 5'7\" tall and weighs 242 pounds. She has been overweight since age 27. She is now at her highest adult weight.\"\"\",\n",
    "    \"\"\"In short, the patient is a 55-year-old gentleman with long-standing morbid obesity, resistant to nonsurgical methods of weight loss with BMI of 69.7 with comorbidities of hypertension, atrial fibrillation, hyperlipidemia, possible sleep apnea, and also osteoarthritis of the lower extremities. On physical examination today, he weighs 514.8 pounds, he has gained 21 pounds since the last visit with us. His pulse is 78, temperature is 97.5, blood pressure is 132/74.\"\"\",\n",
    "    \"\"\"29 y/o male with cerebral palsy, non-shunted hydrocephalus, spastic quadriplegia, mental retardation, bilateral sensory neural hearing loss, severe neurogenic scoliosis and multiple contractures of the 4 extremities, neurogenic bowel and bladder incontinence, and a history of seizures.\n",
    "He was seen for evaluation of seizures which first began at age 27 years, two years before presentation. Spontaneous Vaginal delivery at 36weeks gestation to a G2P1 mother. Birth weight 7#10oz.\"\"\",\n",
    "    \"\"\"Today temperature is 100.1, weight is 73.5 kg, pulse is 84, blood pressure is 121/61, and height is 158. Patient reported temperature of 101 the day before.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Gp_J6e-d-1h"
   },
   "source": [
    "Write the example inputs to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BDl79S_naMP0",
    "outputId": "3e4b611f-6eb7-4f72-f7d2-9e3d1bc16b2f"
   },
   "outputs": [],
   "source": [
    "! rm -r $INPUT_FILE_PATH\n",
    "! mkdir -p $INPUT_FILE_PATH\n",
    "for index, text in enumerate(example_inputs):\n",
    "    excerpt = text[:min(len(text)-10, 100)].replace('\\n', ' ') + \"... \\n\"\n",
    "    write_path = os.path.join(INPUT_FILE_PATH, f'Example{index + 1}.txt')\n",
    "    open(write_path, 'w').write(excerpt + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuJNHIFgeB8A"
   },
   "source": [
    "Read the example inputs back from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlurvjDeaPw_"
   },
   "outputs": [],
   "source": [
    "file_list = os.listdir(INPUT_FILE_PATH)\n",
    "file_paths = [os.path.join(INPUT_FILE_PATH, path) for path in file_list]\n",
    "\n",
    "input_list = []\n",
    "for file_path in file_paths:\n",
    "    text = \"\".join(open(file_path, 'r').readlines()[1:])\n",
    "    input_list.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_-1lrGpeGL4"
   },
   "source": [
    "Transform the inputs to create outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRpRbkPPaFUt"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({'text': input_list}))\n",
    "result = pipeline_model.transform(df).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5fuqq2ReJQ9"
   },
   "source": [
    "Write the outputs to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2isx0tkCZ_Pi",
    "outputId": "c5ded5d5-ceb5-4348-a230-a0a3236b3f8a"
   },
   "outputs": [],
   "source": [
    "! rm -r $OUTPUT_FILE_PATH\n",
    "! mkdir -p $OUTPUT_FILE_PATH\n",
    "\n",
    "def add_or_replace(entity_chunks, new_chunk):\n",
    "    \"\"\"Adds the new entity chunk to the list, unless there is already a chunk\n",
    "    in the same location in the text with equal or greater confidence.\"\"\"\n",
    "    preexisting = False\n",
    "    for index, entity in enumerate(entity_chunks):\n",
    "        if entity[1] == new_chunk[1]:\n",
    "            preexisting = True\n",
    "            if new_chunk[4]['confidenceValue'] > entity[4]['confidenceValue']:\n",
    "                entity_chunks[index] = new_chunk\n",
    "    if not preexisting:\n",
    "        entity_chunks.append(new_chunk)\n",
    "\n",
    "\n",
    "for i in result.index:\n",
    "    # extract all chunks for example i from each entity column\n",
    "    entity_chunks = []\n",
    "    for col in result.columns:\n",
    "        if \"entity\" in col:\n",
    "            for row in result[col].iloc[i]:\n",
    "                add_or_replace(entity_chunks, row)\n",
    "    \n",
    "    # reformat the output to use the 'entity' key for the name of the feature\n",
    "    # instead of 'field' so it is compatible with the NER streamlit app format.\n",
    "    for entity in entity_chunks:\n",
    "        entity[4]['entity'] = entity[4]['field']\n",
    "        del(entity[4]['field'])\n",
    "    \n",
    "    # sort the chunks in order of their first character so they don't display\n",
    "    # out of order\n",
    "    entity_chunks = sorted(entity_chunks, key=lambda x: x[1])\n",
    "    pd.Series({'ner_chunk': entity_chunks}).to_json(\n",
    "        os.path.join(OUTPUT_FILE_PATH, file_list[i].split('.')[0] + '.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "WIc1nZShexVo",
    "outputId": "ab01b0f6-da10-42fc-8daa-21f37bad556d"
   },
   "outputs": [],
   "source": [
    "for example in example_inputs:\n",
    "    annotation_to_html(light_pipeline.fullAnnotate(example))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CONTEXTUAL_PARSER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
