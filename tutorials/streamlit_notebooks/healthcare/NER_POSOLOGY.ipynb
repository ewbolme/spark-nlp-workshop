{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_POSOLOGY.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **Detect drugs and prescriptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uDmeHEFW7_h"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMIDv74CYN0d"
   },
   "source": [
    "Import license keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttHPIV2JXbIM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQtc1CHaYQjU"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGJktFHdHL1n"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj5FRDV4YSXN"
   },
   "source": [
    "Import dependencies into Python and start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sw-t1zxlHTB7"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 2. Select the NER model and construct the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBVZFsTy_9y0"
   },
   "source": [
    "Select the NER model - Posology models: **ner_posology, ner_clinical, ner_jsl**\n",
    "\n",
    "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bj7M9IJz_9ST"
   },
   "outputs": [],
   "source": [
    "# You can change this to the model you want to use and re-run cells below.\n",
    "# Posology models: ner_posology, ner_clinical, ner_jsl\n",
    "# All these models use the same clinical embeddings.\n",
    "MODEL_NAME = \"ner_posology\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zweiG2ilZqoR"
   },
   "source": [
    "Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLuDz_t40be4"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models') \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('embeddings')\n",
    "\n",
    "clinical_ner = NerDLModel.pretrained(MODEL_NAME, 'en', 'clinical/models') \\\n",
    "    .setInputCols(['sentence', 'token', 'embeddings']) \\\n",
    "    .setOutputCol('ner')\n",
    "\n",
    "ner_converter = NerConverter()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "    \"\"\"The patient is a 30-year-old female with a long history of insulin dependent diabetes, type 2; coronary artery disease; chronic renal insufficiency; peripheral vascular disease, also secondary to diabetes; who was originally admitted to an outside hospital for what appeared to be acute paraplegia, lower extremities. She did receive a course of Bactrim for 14 days for UTI. Evidently, at some point in time, the patient was noted to develop a pressure-type wound on the sole of her left foot and left great toe. She was also noted to have a large sacral wound; this is in a similar location with her previous laminectomy, and this continues to receive daily care. The patient was transferred secondary to inability to participate in full physical and occupational therapy and continue medical management of her diabetes, the sacral decubitus, left foot pressure wound, and associated complications of diabetes. She is given Fragmin 5000 units subcutaneously daily, Xenaderm to wounds topically b.i.d., Lantus 40 units subcutaneously at bedtime, OxyContin 30 mg p.o. q.12 h., folic acid 1 mg daily, levothyroxine 0.1 mg p.o. daily, Prevacid 30 mg daily, Avandia 4 mg daily, Norvasc 10 mg daily, Lexapro 20 mg daily, aspirin 81 mg daily, Senna 2 tablets p.o. q.a.m., Neurontin 400 mg p.o. t.i.d., Percocet 5/325 mg 2 tablets q.4 h. p.r.n., magnesium citrate 1 bottle p.o. p.r.n., sliding scale coverage insulin, Wellbutrin 100 mg p.o. daily, and Bactrim DS b.i.d.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv0abcwhXWC-"
   },
   "source": [
    "## 4. Use the pipeline to create outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK1DB9JZaPs3"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQY8tAP6XZJL"
   },
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnsMLq9gctSq"
   },
   "source": [
    "Visualize outputs as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "Ar32BZu7J79X",
    "outputId": "f58e6932-10a8-4636-f014-427e88c2601a"
   },
   "outputs": [],
   "source": [
    "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
    "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
    "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
    "result.select(exploded.alias(\"cols\")) \\\n",
    "    .select(select_expression_0, select_expression_1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wdVmoUcdnAk"
   },
   "source": [
    "Functions to display outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFeu7loodcQQ"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import random\n",
    "\n",
    "def get_color():\n",
    "    r = lambda: random.randint(128,255)\n",
    "    return \"#%02x%02x%02x\" % (r(), r(), r())\n",
    "\n",
    "def annotation_to_html(full_annotation):\n",
    "    ner_chunks = full_annotation[0]['ner_chunk']\n",
    "    text = full_annotation[0]['document'][0].result\n",
    "    label_color = {}\n",
    "    for chunk in ner_chunks:\n",
    "        label_color[chunk.metadata['entity']] = get_color()\n",
    "\n",
    "    html_output = \"<div>\"\n",
    "    pos = 0\n",
    "\n",
    "    for n in ner_chunks:\n",
    "        if pos < n.begin and pos < len(text):\n",
    "            html_output += f\"<span class=\\\"others\\\">{text[pos:n.begin]}</span>\"\n",
    "        pos = n.end + 1\n",
    "        html_output += f\"<span class=\\\"entity-wrapper\\\" style=\\\"color: black; background-color: {label_color[n.metadata['entity']]}\\\"> <span class=\\\"entity-name\\\">{n.result}</span> <span class=\\\"entity-type\\\">[{n.metadata['entity']}]</span></span>\"\n",
    "\n",
    "    if pos < len(text):\n",
    "        html_output += f\"<span class=\\\"others\\\">{text[pos:]}</span>\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-piHygJ6dpEa"
   },
   "source": [
    "Display example outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "AtbhE24VeG_C",
    "outputId": "1b732299-2970-460f-a050-b00a836e4344"
   },
   "outputs": [],
   "source": [
    "for example in input_list:\n",
    "    annotation_to_html(light_pipeline.fullAnnotate(example))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER_POSOLOGY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
