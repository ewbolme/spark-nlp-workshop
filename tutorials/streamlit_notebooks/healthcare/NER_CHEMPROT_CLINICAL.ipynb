{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA21Jo5d9SVq"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_CHEMPROT_CLINICAL.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzIdjHkAW8TB"
   },
   "source": [
    "# **Detect chemical compounds and genes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uDmeHEFW7_h"
   },
   "source": [
    "To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIeCOiJNW-88"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMIDv74CYN0d"
   },
   "source": [
    "Import license keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ttHPIV2JXbIM",
    "outputId": "999d93a1-d9f9-4c5d-8fc7-4f1449ea05e3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
    "jsl_version = license_keys[\"JSL_VERSION\"]\n",
    "\n",
    "print ('SparkNLP Version:', sparknlp_version)\n",
    "print ('SparkNLP-JSL Version:', jsl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQtc1CHaYQjU"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "CGJktFHdHL1n",
    "outputId": "86343214-dc2d-48af-8d84-1f6fc97b5d3e"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==$sparknlp_version\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj5FRDV4YSXN"
   },
   "source": [
    "Import dependencies into Python and start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sw-t1zxlHTB7"
   },
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RgiqfX5XDqb"
   },
   "source": [
    "## 2. Select the NER model and construct the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnLg84PduCRf"
   },
   "source": [
    "Select the NER model\n",
    "\n",
    "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvT2PxSquGlQ"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ner_chemprot_clinical\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zweiG2ilZqoR"
   },
   "source": [
    "Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "LLuDz_t40be4",
    "outputId": "ad607d6e-9e6f-4503-da45-4bd85928fd3a"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models') \\\n",
    "    .setInputCols(['sentence', 'token']) \\\n",
    "    .setOutputCol('embeddings')\n",
    "\n",
    "clinical_ner = NerDLModel.pretrained(MODEL_NAME, 'en', 'clinical/models') \\\n",
    "    .setInputCols(['sentence', 'token', 'embeddings']) \\\n",
    "    .setOutputCol('ner')\n",
    "\n",
    "ner_converter = NerConverter()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Y9GpdJhXIpD"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBOKkB2THdGI"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "    \"\"\"Emerging role of epidermal growth factor receptor inhibition in therapy for advanced malignancy: focus on NSCLC. Combination chemotherapy regimens have emerged as the standard approach in advanced non-small-cell lung cancer. Meta-analyses have demonstrated a 2-month increase in median survival after platinum-based therapy vs. best supportive care, and an absolute 10% improvement in the 1-year survival rate. Just as importantly, cytotoxic therapy has produced benefits in symptom control and quality of life. Newer agents, including the taxanes, vinorelbine, gemcitabine, and irinotecan, have expanded our therapeutic options in the treatment of advanced non-small-cell lung cancer. Despite their contributions, we have reached a therapeutic plateau, with response rates seldom exceeding 30-40% in cooperative group studies and 1-year survival rates stable between 30% and 40%. It is doubtful that substituting one agent for another in various combinations will lead to any further improvement in these rates. The thrust of current research has focused on targeted therapy, and epidermal growth factor receptor inhibition is one of the most promising clinical strategies. Epidermal growth factor receptor inhibitors currently under investigation include the small molecules gefitinib (Iressa, ZD1839) and erlotinib (Tarceva, OSI-774), as well as monoclonal antibodies such as cetuximab (IMC-225, Erbitux). Agents that have only begun to undergo clinical evaluation include CI-1033, an irreversible pan-erbB tyrosine kinase inhibitor, and PKI166 and GW572016, both examples of dual kinase inhibitors (inhibiting epidermal growth factor receptor and Her2). Preclinical models have demonstrated synergy for all these agents in combination with either chemotherapy or radiotherapy, leading to great enthusiasm regarding their ultimate contribution to lung cancer therapy. However, serious clinical challenges persist. These include the identification of the optimal dose(s); the proper integration of these agents into popular, established cytotoxic regimens; and the selection of the optimal setting(s) in which to test these compounds. Both gefitinib and erlotinib have shown clinical activity in pretreated, advanced non-small-cell lung cancer, but placebo-controlled randomized Phase III studies evaluating gefitinib in combination with standard cytotoxic therapy, to our chagrin, have failed to demonstrate a survival advantage compared with chemotherapy alone.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv0abcwhXWC-"
   },
   "source": [
    "## 4. Use the pipeline to create outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK1DB9JZaPs3"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQY8tAP6XZJL"
   },
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnsMLq9gctSq"
   },
   "source": [
    "Visualize outputs as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "Ar32BZu7J79X",
    "outputId": "1d68eb1a-30a1-4f3a-ea7c-08fd30b4ff2c"
   },
   "outputs": [],
   "source": [
    "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
    "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
    "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
    "result.select(exploded.alias(\"cols\")) \\\n",
    "    .select(select_expression_0, select_expression_1).show(truncate=False)\n",
    "result = result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wdVmoUcdnAk"
   },
   "source": [
    "Functions to display outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFeu7loodcQQ"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import random\n",
    "\n",
    "def get_color():\n",
    "    r = lambda: random.randint(128,255)\n",
    "    return \"#%02x%02x%02x\" % (r(), r(), r())\n",
    "\n",
    "def annotation_to_html(full_annotation):\n",
    "    ner_chunks = full_annotation[0]['ner_chunk']\n",
    "    text = full_annotation[0]['document'][0].result\n",
    "    label_color = {}\n",
    "    for chunk in ner_chunks:\n",
    "        label_color[chunk.metadata['entity']] = get_color()\n",
    "\n",
    "    html_output = \"<div>\"\n",
    "    pos = 0\n",
    "\n",
    "    for n in ner_chunks:\n",
    "        if pos < n.begin and pos < len(text):\n",
    "            html_output += f\"<span class=\\\"others\\\">{text[pos:n.begin]}</span>\"\n",
    "        pos = n.end + 1\n",
    "        html_output += f\"<span class=\\\"entity-wrapper\\\" style=\\\"color: black; background-color: {label_color[n.metadata['entity']]}\\\"> <span class=\\\"entity-name\\\">{n.result}</span> <span class=\\\"entity-type\\\">[{n.metadata['entity']}]</span></span>\"\n",
    "\n",
    "    if pos < len(text):\n",
    "        html_output += f\"<span class=\\\"others\\\">{text[pos:]}</span>\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-piHygJ6dpEa"
   },
   "source": [
    "Display example outputs as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "AtbhE24VeG_C",
    "outputId": "c2f0db2d-5a34-4288-b39c-491069800286"
   },
   "outputs": [],
   "source": [
    "for example in input_list:\n",
    "    annotation_to_html(light_pipeline.fullAnnotate(example))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER_CHEMPROT_CLINICAL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
