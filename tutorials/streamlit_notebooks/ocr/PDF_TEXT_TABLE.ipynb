{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-pyfWT3a6S4"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/ocr/PDF_TO_TEXT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWU8Tl9Fa3eT"
   },
   "source": [
    "# Extract Tables from PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DtUIwnIa3eU"
   },
   "source": [
    "To run this yourself, you will need to upload your **Spark OCR** license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAbRkMvtz-Gl"
   },
   "source": [
    "For more in-depth tutorials: https://github.com/JohnSnowLabs/spark-ocr-workshop/tree/master/jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdROQW5ScYKA"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x78T5abRkFaW"
   },
   "source": [
    "Install correct version of Pillow and Restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0h4vKhQfkOqQ",
    "outputId": "878d83ac-5f07-4c8a-b890-bc71eba2396e"
   },
   "outputs": [],
   "source": [
    "# Install correct Pillow version\n",
    "import PIL\n",
    "if PIL.__version__  != '6.2.1':\n",
    "  print ('Installing correct version of Pillow. Kernel will restart automatically')\n",
    "  !pip install --upgrade pillow==6.2.1\n",
    "  # hard restart runtime\n",
    "  import os\n",
    "  os.kill(os.getpid(), 9)\n",
    "else:\n",
    "  print ('Correct Pillow detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeMJ4AoPkoMc"
   },
   "source": [
    "Read licence key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fUeMlVj1a3eV",
    "outputId": "b8235663-f849-4cea-bf45-3f88123a241b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('./spark_ocr.json', 'r') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "secret = license_keys['JSL_OCR_SECRET']\n",
    "os.environ['JSL_OCR_LICENSE'] = license_keys['SPARK_OCR_LICENSE']\n",
    "version = ocr_secret.split('-')[0]\n",
    "print ('Spark OCR Version:', version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74VqnE1reEFC"
   },
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErndQ8oea3eY"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "!apt-get update\n",
    "!apt-get install -y openjdk-8-jdk\n",
    "!java -version\n",
    "\n",
    "# Install pyspark, SparkOCR, and SparkNLP\n",
    "!pip install --ignore-installed -q pyspark==2.4.4\n",
    "# Insall Spark Ocr from pypi using secret\n",
    "!python -m pip install --upgrade spark-ocr==$version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "# or install from local path\n",
    "# %pip install --user ../../python/dist/spark-ocr-[version].tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVt8BQaaeGp5"
   },
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn4in75Ha3eb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Pyspark Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Necessary imports from Spark OCR library\n",
    "from sparkocr import start\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.enums import *\n",
    "from sparkocr.utils import display_image, to_pil_image\n",
    "from sparkocr.metrics import score\n",
    "import pkg_resources\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAnLt26eMHu"
   },
   "source": [
    "Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "BXtlGP0aa3ee",
    "outputId": "26afc061-ebc3-4384-ecb3-31d548a59405"
   },
   "outputs": [],
   "source": [
    "spark = start(secret=secret)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6caZBlia3et"
   },
   "source": [
    "## 2. Read a sample pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6KK40-Q2NA0"
   },
   "outputs": [],
   "source": [
    "\n",
    "pdf_example = pkg_resources.resource_filename('sparkocr', 'resources/ocr/pdfs/tabular-pdf/data.pdf')\n",
    "pdf_example_df = spark.read.format(\"binaryFile\").load(pdf_example).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ApsEfUpfa3eu",
    "outputId": "df7ded24-a5e6-472e-89c5-8df8245daa1b"
   },
   "outputs": [],
   "source": [
    "image_df = PdfToImage() \\\n",
    "    .setInputCol(\"content\") \\\n",
    "    .setOutputCol(\"image\") \\\n",
    "    .transform(pdf_example_df.select(\"content\", \"path\"))\n",
    "for r in image_df.limit(1).collect():\n",
    "    display_image(r.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxZlmX-ieyqE"
   },
   "source": [
    "## 3. Extract tables from PDF using a sinlge transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9vo_4vua3er"
   },
   "outputs": [],
   "source": [
    "pdf_to_text_table = PdfToTextTable()\n",
    "pdf_to_text_table.setInputCol(\"content\")\n",
    "pdf_to_text_table.setOutputCol(\"table\")\n",
    "pdf_to_text_table.setMethod(\"basic\")\n",
    "pdf_to_text_table.setGuess(True)\n",
    "\n",
    "\n",
    "table = pdf_to_text_table.transform(pdf_example_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd74DK4ha3ew"
   },
   "source": [
    "## 4. Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnCgi8I9QlS2"
   },
   "source": [
    "### Raw result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "o5Wh9ysOa3ew",
    "outputId": "dcabf64c-5150-490f-9068-df370681cca4"
   },
   "outputs": [],
   "source": [
    "\n",
    "table.select(table[\"table.chunks\"].getItem(0)[\"chunkText\"]).show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uC_egLWa3ez"
   },
   "source": [
    "### Convert to table and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkVAp3CkQzf_"
   },
   "outputs": [],
   "source": [
    "res = table.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PS81lt74Q0qA"
   },
   "outputs": [],
   "source": [
    "# extract ALL tables and create dataframes\n",
    "dfs = []\n",
    "for docu in res['table'].values:\n",
    "    rows = []\n",
    "    for page in docu[1]:\n",
    "        cols = []\n",
    "        for row in page:\n",
    "            #print (row[0])\n",
    "            cols.append(str(row[0]))\n",
    "        rows.append(cols)\n",
    "\n",
    "    rows = np.asarray(rows)\n",
    "\n",
    "    df = pd.DataFrame(rows[1:], columns=rows[0])\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iAG4uVkRREed",
    "outputId": "6edfbe59-51bc-48a1-f072-b804617e6a4b"
   },
   "outputs": [],
   "source": [
    "#first dataframe in list of dataframes\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "un_nwbt4Q92U",
    "outputId": "4929b11d-30a6-46f5-9f7e-6170545058b6"
   },
   "outputs": [],
   "source": [
    "#print all\n",
    "for df in dfs:\n",
    "  print (df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PDF_TEXT_TABLE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
