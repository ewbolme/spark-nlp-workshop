{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7p69LnaldJa_"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83aGge0ndJbB"
   },
   "source": [
    "# Use pretrained `explain_document` Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49109,
     "status": "ok",
     "timestamp": 1568996489923,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "pVycMjc1dLIe",
    "outputId": "119d0133-503b-43af-a4c2-0fa4da502264"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOeiIKN1dJbC"
   },
   "source": [
    "### Stages\n",
    "\n",
    " * DocumentAssembler\n",
    " * SentenceDetector\n",
    " * Tokenizer\n",
    " * Lemmatizer\n",
    " * Stemmer\n",
    " * Part of Speech\n",
    " * SpellChecker (Norvig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwzCcMrkdJbE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "#Spark ML and SQL\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cV-HCwyqdJbI"
   },
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72214,
     "status": "ok",
     "timestamp": 1568996513047,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "GxPGe1DEdJbK",
    "outputId": "64e807df-416c-408e-d21e-f907ccfebac1"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3zO5qw3dJbO"
   },
   "source": [
    "#### This is our testing document, we'll use it to exemplify all different pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6VlR5wWdJbP"
   },
   "outputs": [],
   "source": [
    "testDoc = [\n",
    "\"French author who helped pioner the science-fiction genre. \\\n",
    "Verne wrate about space, air, and underwater travel before \\\n",
    "navigable aircrast and practical submarines were invented, \\\n",
    "and before any means of space travel had been devised. \"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104704,
     "status": "ok",
     "timestamp": 1568996545547,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "bMWRxstQdJbR",
    "outputId": "924b895d-553f-49fa-dc8c-a63a7160fe01"
   },
   "outputs": [],
   "source": [
    "pipeline = PretrainedPipeline('explain_document_ml', lang='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUE9Pnw_dJbU"
   },
   "source": [
    "#### We are not interested in handling big datasets, let's switch to LightPipelines for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6atL1g_UdJbV"
   },
   "outputs": [],
   "source": [
    "result = pipeline.annotate(testDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WLmPeANdJbX"
   },
   "source": [
    "#### Let's analyze these results - first let's see what sentences we detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105667,
     "status": "ok",
     "timestamp": 1568996546519,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "GBQLpz4EdJbY",
    "outputId": "b0ba2294-b65d-4aa4-c1d0-c3c3a51e89b1"
   },
   "outputs": [],
   "source": [
    "[content['sentence'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89vjlh-CdJbb"
   },
   "source": [
    "#### Now let's see how those sentences were tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105663,
     "status": "ok",
     "timestamp": 1568996546521,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "G1PAPYxidJbb",
    "outputId": "c5e74e3f-0307-49b7-f074-2aefbae11c82"
   },
   "outputs": [],
   "source": [
    "[content['token'] for content in result] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Etpy_GS6dJbe"
   },
   "source": [
    "#### Notice some spelling errors? the pipeline takes care of that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105657,
     "status": "ok",
     "timestamp": 1568996546521,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "hh9aebz8dJbf",
    "outputId": "f7c5850f-04c8-4beb-94df-d25c684fdd01"
   },
   "outputs": [],
   "source": [
    "[content['spell'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU-UNS8AdJbh"
   },
   "source": [
    "#### Now let's see the lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105651,
     "status": "ok",
     "timestamp": 1568996546522,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "fHgN1eOkdJbi",
    "outputId": "9f4c6513-abc8-4ea7-a1a1-3521b9f68081"
   },
   "outputs": [],
   "source": [
    "[content['lemmas'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eCXgmSYdJbk"
   },
   "source": [
    "#### Let's check the stems, any difference with the lemmas shown bebore?\n",
    "\n",
    "[content['lemmas'] for content in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105644,
     "status": "ok",
     "timestamp": 1568996546522,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "B-rn3_sodJbl",
    "outputId": "1409efb5-5bba-447a-97e9-700b61895ea0"
   },
   "outputs": [],
   "source": [
    "[content['stems'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "818sKySUdJbo"
   },
   "source": [
    "#### Now it's the turn on Part Of Speech(POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105638,
     "status": "ok",
     "timestamp": 1568996546523,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "Hnd1vUzodJbo",
    "outputId": "96cc186a-8e5c-4451-dcc2-58bc55c0b107"
   },
   "outputs": [],
   "source": [
    "pos = [content['pos'] for content in result]\n",
    "token = [content['token'] for content in result]\n",
    "# let's put token and tag together\n",
    "list(zip(token[0], pos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbJZWBVadJbr"
   },
   "source": [
    "# Use pretrained `match_chunk` Pipeline for Individual Noun Phrase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCYGDKLCdJbs"
   },
   "source": [
    "* DocumentAssembler\n",
    "* SentenceDetector\n",
    "* Tokenizer\n",
    "* Part of speech\n",
    "* chunker\n",
    "\n",
    "Pipeline:\n",
    "* The pipeline uses regex `<DT>?<JJ>*<NN>+`\n",
    "* which states that whenever the chunk finds an optional determiner \n",
    "* (DT) followed by any number of adjectives (JJ) and then a noun (NN) then the Noun Phrase(NP) chunk should be formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116016,
     "status": "ok",
     "timestamp": 1568996556907,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "g0bA6ADsdJbt",
    "outputId": "b356fe38-946c-4657-96ac-83b8b780010d"
   },
   "outputs": [],
   "source": [
    "pipeline = PretrainedPipeline('match_chunks', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnW9ditjdJbv"
   },
   "outputs": [],
   "source": [
    "result = pipeline.annotate(\"The book has many chapters\") # single noun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116016,
     "status": "ok",
     "timestamp": 1568996556912,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "8RAa24DXdJbx",
    "outputId": "be95765b-9dce-4eb7-9a78-f0d34474b0b3"
   },
   "outputs": [],
   "source": [
    "result['chunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zPjsztSdJb0"
   },
   "outputs": [],
   "source": [
    "result = pipeline.annotate(\"the little yellow dog barked at the cat\") #multiple noune phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116142,
     "status": "ok",
     "timestamp": 1568996557047,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "9VkV1fwZdJb2",
    "outputId": "b83e101d-a235-4eb4-8d11-dd8e9ec0125a"
   },
   "outputs": [],
   "source": [
    "result['chunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1- How to use Light Pipelines.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
